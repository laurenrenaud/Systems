---
title: "Machine Learning for Extract Classification"
author: "Lauren Renaud & Krista Kinnard"
date: "May, 2017"
output: html_document
---

```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(RColorBrewer)
library(tidyr)
library(topicmodels)
options(scipen=4)

# how to build extracts file ----------
# dispensing <- readr::read_csv("../data/Dec2016/biotrackthc_dispensing.csv")
# dispensing$saledate <- as.Date(as.POSIXct(dispensing$sessiontime,
#                                          origin = "1970-01-01", tz="America/Los_Angeles"))
# inventory <- readr::read_csv("../data/Dec2016/biotrackthc_inventory.csv")
# 
# extracts <- dispensing %>%
#   # 24 is inventory type for extracts
#   dplyr::filter(inventorytype==24) %>%
#   dplyr::select(dispensingid = id, weight, inventoryid, price, usableweight, saledate) %>%
#   dplyr::left_join(select(inventory, inventoryid = id, strain, productname,
#                           inventoryparentid, sample_id),
#                    by="inventoryid") %>%
#   dplyr::mutate(price_x = ifelse(saledate >= "2015-07-01",
#                                  price*1.37,
#                                  price),
#                 price_per_gram = price_x/usableweight) %>%
#   dplyr::select(-(saledate), -(price))
# 
# # get names from categorization function -----
# # first get list/df of inhalantnames
# inhalantnames <- as.data.frame(unique(extracts$productname))
# # rename column so we can call it
# colnames(inhalantnames) <- "productname"
# # bringing in classification function
# source("categorization_function.R")
# inhalantnames <- inhalantnames %>%
#   filter(!is.na(productname)) %>%
#   rowwise() %>%
#   mutate(inhalant_type = categorizeNames(productname),
#          inhalant_gen = groupProductTypes(inhalant_type),
#          inhalant_genOil = groupProductTypesOilSep(inhalant_type))
# # join classified inhalantnames back to dispening df
# extracts$productname <- as.factor(extracts$productname)
# extracts <- left_join(extracts, inhalantnames, by="productname")
# 
# write.table(extracts, file="../data/Dec2016/cleaned/samples/extracts.csv", sep=",", row.names=F)

# pull in data -------
extracts <- readr::read_csv("../data/Dec2016/cleaned/samples/extracts.csv")
extracts$inventoryparentid <- as.numeric(extracts$inventoryparentid)
extracts$sample_id <- as.numeric(extracts$sample_id)
potency <- readr::read_csv("../data/Dec2016/biotrackthc_labresults_potency_analysis.csv")
micro <- readr::read_csv("../data/Dec2016/biotrackthc_labresults_micro_screening.csv")
moisture <- readr::read_csv("../data/Dec2016/biotrackthc_labresults_moisture_content.csv")
solvent <- readr::read_csv("../data/Dec2016/biotrackthc_labresults_solvent_screening.csv")
inv_types <- readr::read_csv("../data/Dec2016/cleaned/inventory_type.csv")
# combine the non-potency tests
tests <- rbind(micro, moisture, solvent)
labkey <- readr::read_csv("../data/Dec2016/biotrackthc_labresults_samples.csv")
labkey$inventoryid <- as.numeric(labkey$inventoryid)

potency <- readr::read_csv("../data/Dec2016/biotrackthc_labresults_potency_analysis.csv")
potency_tidy <- potency %>%
  # was going to use tidyr to spread variable names but some sample_ids have up to 15 tests
  # so summarizing first, assuming max() is most accurate and that others might be missing
  # values but need to check
  dplyr::group_by(sample_id, name) %>%
  dplyr::summarise(value = max(value)) %>%
  # spread to get column each for THC, THCA, CBD, Total
  tidyr::spread(name, value) %>%
  # CBDA was a column of all null or 0
  dplyr::select(-(CBDA), -(THC), -(THCA)) %>%
  dplyr::left_join(select(labkey, sample_id = id, inventoryid, inventoryparentid),
                   by="sample_id") %>%
  dplyr::ungroup() 


tests <- tests %>%
  dplyr::left_join(select(labkey, sample_id = id, inventoryparentid), by="sample_id") %>%
  dplyr::group_by(inventoryparentid, name) %>%
  # getting max value to handle that some have multiple tests run,
  # which may be error in the data
  dplyr::summarise(
    value = max(value)
  ) %>%
  tidyr::spread(name, value) %>%
  dplyr::group_by(inventoryparentid) %>%
  dplyr::summarise(
    bacteria = !is.na(aerobic_bacteria),
    bile = !is.na(bile_tolerant),
    coliforms = !is.na(coliforms),
    ecoli = !is.na(e_coli_and_salmonella),
    yeast = !is.na(yeast_and_mold),
    moisture = !is.na(moisture),
    solvent = !is.na(residual_solvent)
  ) %>%
  dplyr::left_join(potency_tidy, by="inventoryparentid")

# convert to numeric from TRUE / FALSE
tests_numeric <- tests * 1

# get df of lab data types to add to test df
lab_invtypes <- labkey %>%
  dplyr::group_by(inventoryparentid) %>%
  # handles the 8 inventory types that have more than one type listed
  dplyr::summarise(inventorytype = inventorytype[1]) %>%
  dplyr::left_join(inv_types, by="inventorytype") %>%
  dplyr::select(-(inventorytype), lab_invtype = inv_type_name)

# trying going from extracts to labs
tests_extracts <- extracts %>%
  dplyr::select(sample_id, price_x, price_per_gram,
                inhalant_type, inhalant_gen, productname) %>%
  dplyr::left_join(tests_numeric, by=c("sample_id" = "inventoryid")) %>%
  dplyr::select(-(sample_id.y)) 


# testing
sum(is.na(tests_extracts$price_per_gram)) / nrow(tests_extracts)
# WHY IS THIS HIGHER? ##
sum(is.na(tests_extracts$Total)) / nrow(tests_extracts)

# join the lab's inventory types back to the tests df
# tests_extracts <- tests_extracts %>%
#   dplyr::left_join(lab_invtypes, by="inventoryparentid") 


# productname and therefore classification type are missing from about 10% of these
# it's also missing from 13% of the extracts df
# price is missing from 5%
# potency is missing from 5%
tests_nomissing <- dplyr::filter(tests_extracts, !(is.na(price_per_gram)), !(is.na(CBD)), 
                               !(is.na(Total)),
                               # calculation for price per gram will be more accurate
                               price_per_gram>0)

tests_nomissing$inhalant_gen <- as.factor(tests_nomissing$inhalant_gen)
tests_nomissing$inhalant_type <- as.factor(tests_nomissing$inhalant_type)
#tests_nomissing$lab_invtype <- as.factor(tests_nomissing$lab_invtype)


```


```{r labtypes}
# 
# # lab types heat maps ------
# labtypes_heat <- tests_extracts %>%
#   dplyr::left_join(lab_invtypes, by="inventoryparentid") %>%
#   dplyr::group_by(lab_invtype) %>%
#   dplyr::mutate(lab_type_count = n()) %>%
#   dplyr::ungroup() %>%
#   dplyr::group_by(lab_invtype, inhalant_gen) %>%
#   dplyr::summarise(count = n(),
#                    `% in Lab Inv Type` = count / lab_type_count[1])
# 
# # heat map of % of retail type that are of each lab inventory type
# # dropping uncategorized and flower to focus on testing if
# # these will help us categorize other things
# labtypes_heat %>%
#   dplyr::filter(lab_invtype!="Flower Lot", !is.na(inhalant_gen), inhalant_gen!="Uncategorized") %>%
#   # dplyr::filter(lab_invtype!="Flower Lot", !is.na(lab_invtype), !is.na(inhalant_gen),
#   #               inhalant_gen!="Uncategorized", lab_invtype!="Marijuana Extract for Inhalation") %>%
#   ggplot(aes(y = inhalant_gen, x = lab_invtype)) +
#   geom_tile(aes(fill = `% in Lab Inv Type`), colour = "white") +
#   scale_fill_gradient(low = "lightcyan2", high = "turquoise4") +
#   labs(title="Retail Type by Lab Type",
#        x="Lab Type",
#        y="Retail Type") +
#   theme(panel.grid.major.y = element_blank(), panel.grid.major.x = element_blank(),
#         panel.background = element_rect(fill = "gray99"),
#         axis.text.x = element_text(angle = 10, hjust = 0.8, vjust = 0.9))
# 
# #limited to distribution of uncatergorized
# labtypes_heat %>%
#   dplyr::filter(inhalant_gen=="Uncategorized") %>%
#   ggplot(aes(y = inhalant_gen, x = lab_invtype)) +
#   geom_tile(aes(fill = `% in Lab Inv Type`), colour = "white") +
#   scale_fill_gradient(low = "lightcyan2", high = "turquoise4") +
#   labs(title="Retail Type by Lab Type",
#        x="Lab Type",
#        y="Retail Type") +
#   theme(panel.grid.major.y = element_blank(), panel.grid.major.x = element_blank(),
#         panel.background = element_rect(fill = "gray99"),
#         axis.text.x = element_text(angle = 10, hjust = 0.8, vjust = 0.9))

```

After classifying based on search strings, we wanted to see if there were other text classifications that we had not found. First we made a word cloud to see what words and phrases showed up most often in the product names of the unclassified.

```{r wordcloud}

# word cloud uncategroized -----
library(tm)
library(SnowballC)
library(wordcloud)
# Load the data as a corpus

uncategorized <- dplyr::filter(extracts, inhalant_gen=="Uncategorized")

inhal_names <- unique(uncategorized$productname)
docs <- Corpus(VectorSource(inhal_names))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")

# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)

wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=300, random.order=TRUE, rot.per=0.4, 
          colors=brewer.pal(12, "Paired"))

# # without product "type" keywords
# d.2 <- dplyr::filter(d, word !="cartridge" & word!="wax" & word!="vape" & word!="shatter" &
#                        word!="cart" & word!="gram")

```

To explore the text in these names in more depth, we used tried topic modeling using [Latent Dirichlet allocation](http://tidytextmining.com/topicmodeling.html#latent-dirichlet-allocation).

```{r lda_text}

# LDA text -------

# LDA : Latent Dirichlet allocation
# http://tidytextmining.com/topicmodeling.html
# http://tidytextmining.com/tidytext.html

# 1: convert strings into dataframe
# and need to include which "line" it comes from
#productnames.df <- data_frame(line=1:nrow(extracts), text = extracts$productname)
# 2: use tidytext to convert into one-token-per-document-per-row.
library(tidytext)
library(stringr)
# this then includes a variable saying which line it initially came from
# removed.df <- removed.df %>%
#   unnest_tokens(word, text)

names.df <- extracts %>%
  dplyr::filter(!is.na(productname)) %>%
  dplyr::mutate(linenumber = row_number())
# sampling to run on smaller df
# sample.list <- sample(names.df$dispensingid, 200000, replace=F)
# names.sample <- dplyr::filter(names.df, dispensingid %in% sample.list)
# names.sample$productname <- as.character(names.sample$productname)

# or sampling only uncategorized
sample.list <- sample(names.df$dispensingid[names.df$inhalant_gen=="Uncategorized"],
                      200000, replace=F)
names.sample <- dplyr::filter(names.df, dispensingid %in% sample.list)
names.sample$productname <- as.character(names.sample$productname)

names.tidy <- names.sample %>%
  unnest_tokens(word, productname)

# remove stop words (but should check those)
stop_words <- as.data.frame(c("gram", "grams", "g", "mg", "oz", "0.5g", "1g", "5g",
                              "500mg", 0:9))
colnames(stop_words) <- "word"
names.tidy <- names.tidy %>%
  dplyr::anti_join(stop_words)

# create DocumentTermMatrix
names.docmatrix <- names.tidy %>%
  select(document = linenumber, term = word) %>%
  group_by(document, term) %>%
  summarise(count = n()) %>%
  cast_dtm(document, term, count)

ap_lda <- LDA(names.docmatrix, k = 6, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

# ap_documents <- tidy(ap_lda, matrix = "gamma")
# ap_documents %>%
#   filter(topic==2) %>%
#   arrange(desc(gamma))

```

It appears the text in the names of these unclassified products are not indicitive of their product types. From reading through, they seem to mostly be strain names or other simplified names that do not give enough detail about their type.

We then decided to use other characteristics of the products for classification. We hypothesize that the following characteristics may be indicitive of product type:

 - Potency (Total THC and CBD): Some product tend to have higher potency levels, like wax and shatter, while products like hash and keif are very rarely, if ever, at the high end of the potency scales.
 - Price per gram: Some products are cheaper to produce, or use otherwise "leftover" materials, like hash and keif, while something like a vape pen cartridge is not only highly processed but is also manufactured into a cartridge and therefore has a higher cost.
 - Which laboratory tests the product received: Not all tests are required for all products. Therefore having received a specific laboratory test may be indicitive of the product type. For example, hash and keif do not generally receive solvent tests, because their extraction method does not involve solvent.

First we tried an unsupervised learning method. We wanted to cluster products by using these variables, and compare these clusters to what our text classification method created.

```{r unsupervised_cluster}

# test and train -------
# Randomly select 20% of the data to be held out for model validation
train <- sample(1:nrow(tests_nomissing), 
                round(0.2 * nrow(tests_nomissing)))
test <- setdiff(1:nrow(tests_nomissing), train)

tests.train <- tests_nomissing[train,]
tests.test <- tests_nomissing[test,]
# train.def <- tests_numeric$inhalant_gen[train]
# test.def <- tests_numeric$inhalant_gen[test]

# k means -----
set.seed(427)
# km.out <- kmeans(tests.train[,c(3, 8:16)], 3, nstart = 20)
# # join clusters back to df
# tests.train$cluster <- km.out$cluster
# 
# table(tests.train$cluster, tests.train$inhalant_gen)
# 
# # removing outliers
# outliers <- filter(tests.train, 
#                    #inhalant_type=="Uncategorized", 
#                    cluster==1)
# tests.train <- filter(tests.train, !(inventoryparentid %in% outliers$inventoryparentid))
# 
# km.out <- kmeans(tests.train[, c(3, 8:16)], 3, nstart = 20)
# # join clusters back to df
# tests.train$cluster <- km.out$cluster
# table(tests.train$cluster, tests.train$inhalant_gen)
# table(tests.train$cluster, tests.train$inhalant_type)

# only on classified ------
classified <- filter(tests_nomissing, inhalant_gen!="Uncategorized")
train <- sample(1:nrow(classified), 
                round(0.2 * nrow(classified)))
test <- setdiff(1:nrow(classified), train)

tests.train <- classified[train,]
tests.test <- classified[test,]

km.out <- kmeans(tests.train[,c(3, 8:16)], 3, nstart = 20)
# join clusters back to df
tests.train$cluster <- km.out$cluster
# table(tests.train$cluster, tests.train$inhalant_gen)

# removing outliers
outliers <- filter(tests.train, 
                   #inhalant_type=="Uncategorized", 
                   cluster==2)
tests.train <- filter(tests.train, !(inventoryparentid %in% outliers$inventoryparentid))

km.out <- kmeans(tests.train[, c(3, 8:16)], 3, nstart = 20)
# join clusters back to df
tests.train$cluster <- km.out$cluster
table(tests.train$cluster, tests.train$inhalant_gen)
table(tests.train$cluster, tests.train$inhalant_type)
```

It appears that clustering on these variables alone is not indicitive enough of product types. While we do not have absolute ground truth, the text classification has been accepted by subject matter experts from the RAND research team and others in Washington State. Therefore, we can use those categories as approximate ground truth for a supervised machine learning model that combines these variables with the text classification. 


```{r knn_1}
# uncategorized df -----
# samplelist <- sample(tests_nomissing$inventoryparentid, 200, replace=F)
# tests_sampled <- dplyr::filter(tests_nomissing, productname %in% samplelist)

avg_by_name <- tests_nomissing %>%
  dplyr::mutate(productname = as.factor(productname),
                price_per_gram = as.numeric(price_per_gram)) %>%
  group_by(productname) %>%
  summarise(
    inhalant_gen = inhalant_gen[1],
    bacteria = median(bacteria, na.rm=T),
    bile = mean(bile, na.rm=T),
    coliforms = mean(coliforms, na.rm=T),
    ecoli = mean(ecoli, na.rm=T),
    yeast = mean(yeast, na.rm=T),
    moisture = mean(moisture, na.rm=T),
    solvent = mean(solvent, na.rm=T),
    CBD = median(CBD, na.rm=T),
    Total = median(Total, na.rm=T),
    price_per_gram = median(price_per_gram, na.rm=T)
  )

# samplelist <- sample(avg_by_name$productname, 2000, replace=F)
# tests_sampled <- dplyr::filter(avg_by_name, productname %in% samplelist)
# 
# uncategorized <- filter(tests_sampled, inhalant_gen=="Uncategorized")
# classified <- filter(tests_sampled, inhalant_gen!="Uncategorized", !is.na(inhalant_gen))


uncategorized <- filter(avg_by_name, inhalant_gen=="Uncategorized")
classified <- filter(avg_by_name, inhalant_gen!="Uncategorized", !is.na(inhalant_gen))



# k nearest neighbors ---------
library(class)
# Randomly select 20% of the data to be held out for model validation
train <- sample(1:nrow(classified), 
                round(0.2 * nrow(classified)))
test <- setdiff(1:nrow(classified), train)

tests.train <- classified[train, c(3:12)]
tests.test <- classified[test, c(3:12)]
train.def <- classified$inhalant_gen[train]
test.def <- classified$inhalant_gen[test]
knn.pred <- knn(tests.train, tests.test, train.def, k=4)

# joining back to definitions
classifed_predictions <- cbind(tests.test, knn.pred, test.def)
table(classifed_predictions$knn.pred, classifed_predictions$test.def)

# using model on unclassified
uncat <- uncategorized[, c(3:12)]
knn.pred <- knn(tests.train, uncat, train.def, k=4)
uncat_predictions <- cbind(uncat, knn.pred, uncategorized$productname)
head(uncat_predictions)
table(uncat_predictions$knn.pred)

uncat_pred_byname <- uncat_predictions %>%
  dplyr::select(productname = `uncategorized$productname`, inhalant_gen = knn.pred)

uncategorized <- extracts %>%
  dplyr::filter(inhalant_gen=="Uncategorized") %>%
  dplyr::select(dispensingid, productname) %>%
  dplyr::left_join(uncat_pred_byname, by="productname") %>%
  dplyr::select(-(productname)) 

table(uncategorized$inhalant_gen)
sum(is.na(uncategorized$inhalant_gen))

categorized <- extracts %>%
  dplyr::filter(inhalant_gen!="Uncategorized") %>%
  dplyr::select(dispensingid, inhalant_gen)

full_count <- rbind(uncategorized, categorized)

table(full_count$inhalant_gen)
sum(is.na(full_count$inhalant_gen)) / nrow(full_count)


```





```{r knn}
# 
# # k nearest neighbors ---------
# library(class)
# # Randomly select 20% of the data to be held out for model validation
# train <- sample(1:nrow(classified), 
#                 round(0.2 * nrow(classified)))
# test <- setdiff(1:nrow(classified), train)
# 
# tests.train <- classified[train, c(2:10, 12)]
# tests.test <- classified[test, c(2:10, 12)]
# train.def <- classified$inhalant_gen[train]
# test.def <- classified$inhalant_gen[test]
# knn.pred <- knn(tests.train, tests.test, train.def, k=4)
# 
# # joining back to definitions
# classifed_predictions <- cbind(tests.test, knn.pred, test.def)
# table(classifed_predictions$knn.pred, classifed_predictions$test.def)
# 
# # using model on unclassified
# uncat <- uncategorized[, c(2:10, 12)]
# knn.pred <- knn(tests.train, uncat, train.def, k=5)
# uncat_predictions <- cbind(uncat, knn.pred, uncategorized$productname)
# head(uncat_predictions)
# table(uncat_predictions$knn.pred)

```

```{r }



# trying to find variable importance
#knn.pred$results$Rsquared
#   
# # trying to plot accuracy
# # from: https://rpubs.com/potentialwjy/MachineLearning3
# # Load the class package, define range and accs
# library(class)
# range <- 1:round(0.2 * nrow(tests.train))
# accs <- rep(0, length(range))
# 
# for (k in range) {
#   # Make predictions using knn: pred
#   pred <- knn(tests.train, tests.test, train.def, k=k)
#   # Construct the confusion matrix: conf
#   conf <- table(test.def, pred)
#   # Calculate the accuracy and store it in accs[k]
#   accs[k] <- sum(diag(conf)) / sum(conf)
#   }
# 
# # Plot the accuracies. Title of x-axis is "k".
# plot(range, accs, xlab="k")



# features <- function(df, m = 1){
#   nf <- ncol(df) -1 # number of input features
#   idx <- 1: nf  # column indices of input features
#   output <- df[, ncol(df)]  # output column
#   outputH <- entropy(output) # entropy for output
#   idx.list <- combn(idx, m) # matrix storing all combinations of size m from idx
#   IG.res <-NULL # output data frame
#   # iterate through all combinations of index
#   for (ii in 1:ncol(idx.list)){
#     this.idx <- idx.list[, ii]
#     input.df <- data.frame(df[,this.idx])
#     # create a vector where each element is a concatenation of all values of a row of a data frame
#     this.input <- apply(input.df, 1, paste, collapse='')
#     # create a new feature name which is a concatenation of feature names in a feature set
#     this.input.names <- paste(names(df)[this.idx], collapse=' ')
#     this.IG <-info.gain(this.input,output) # information gain
#     this.RIG <- this.IG / outputH # relative information gain
#     this.res <- data.frame(feature = this.input.names, IG = this.IG, RIG = this.RIG) #assemble a df
#     IG.res <- rbind(IG.res, this.res) # concatenate the results
#   }
#   sorted <- IG.res[order(-IG.res$IG), ] # sort the result by information gain in a descending order
#   return (sorted)
# }
# 
# features(classifed_predictions, m=12)

# 
# 
# #returns IG for categorical variables.
# IG_cat<-function(data,feature,target){
#   #Strip out rows where feature is NA
#   data<-data[!is.na(data[,feature]),] 
#   #use ddply to compute e and p for each value of the feature
#   dd_data<-ddply(data, feature, here(summarise), e=entropy(get(target)), N=length(get(target)))
#   #compute entropy for the parent
#   e0<-entropy(data[,target])
#   #calculate p for each value of feature
#   dd_data$p<-dd_data$N/nrow(data)
#   #compute IG
#   IG<-e0-sum(dd_data$p*dd_data$e)
#   
#   return(IG)
# }








# # random forests -------
# library(randomForest)
# extracts.rf <- randomForest(inhalant_gen ~ bacteria + bile + coliforms + ecoli + yeast + moisture +
#                               solvent + price_per_gram + CBD + Total, ntree=30, 
#                             data=classified, importance=TRUE)
# 
# extracts.rf <- randomForest(inhalant_gen ~ bacteria + bile + coliforms + ecoli + yeast + moisture +
#                               solvent + price_per_gram + CBD + Total, ntree=30, 
#                             data=classified, importance=TRUE)
# plot(road.rf)
# var.imp.road <- varImpPlot(road.rf)
# rownames(var.imp.road)[1:4]
# 
# table(tests_numeric$inhalant_gen)


# 
# # sankey of classification --------
# 
# sankey.df <- filter(extracts, !is.na(inhalant_gen))
# sankey.df$inhalant_gen <- as.character(sankey.df$inhalant_gen)
# sankey.df$inhalant_type <- as.character(sankey.df$inhalant_type)
# edges <- sankey.df %>%
#   # renaming uncategorized to unknown
#   # because the riverplot can't handle matching names
#   dplyr::mutate(inhalant_type2 = ifelse(inhalant_type=="Uncategorized", "Unknown", inhalant_type)) %>%
#   dplyr::group_by(inhalant_gen, inhalant_type2) %>%
#   dplyr::summarise(
#     #total_products = "All Products",
#     count_products = n()
#   ) %>%
#   as.data.frame()
# 
# colnames(edges) <- c("N1", "N2", "Value")
# 
# nodes <- data.frame(
#   ID = c(unique(edges$N1), unique(edges$N2)), stringsAsFactors= FALSE,
#   col = c(rep("#e8008077", length(unique(sankey.df$inhalant_type))), 
#           rep("#4a7aff77", length(unique(sankey.df$inhalant_gen))))
# )
# 
# riv <- makeRiver(nodes, edges, 
#                  node_xpos=c(rep.int(1,length(unique(edges$N1))), 
#                              rep.int(2,length(unique(edges$N2)))))
# 
# # style the riverplot
# riv.style <- riverplot::default.style()
# riv.style$textcex <- 0.7
# riv.style$srt <- 0
# riv.style$nodestyle <- "regular"
# riv.style$textcol <- "#39383a"
# #riv.style$edgecol$col <- "#FF0000"
# #riv.style$colorRampPaletteAlpha( c( "#FF000033", "#00FF0099" ) )( 5 )
# plot(riv, default_style=riv.style, node_margin=0.2, plot_area=1, xscale=0.92)
# text(-.1, .5, "Product Groupings", col= "#333333", cex=0.8, srt = 90)
# text(1, .5, "Product Types", col= "#333333", srt = 270, cex=0.8)



# # adding more edges and nodes
# sankey.df <- filter(extracts, !is.na(inhalant_gen))
# sankey.df$inhalant_gen <- as.character(sankey.df$inhalant_gen)
# sankey.df$inhalant_type <- as.character(sankey.df$inhalant_type)
# edges <- sankey.df %>%
#   # renaming uncategorized to unknown
#   # because the riverplot can't handle matching names
#   dplyr::mutate(inhalant_type2 = ifelse(inhalant_type=="Uncategorized", "Unknown", inhalant_type)) %>%
#   dplyr::group_by(inhalant_gen) %>%
#   dplyr::mutate(count_groupings = n()) %>%
#   dplyr::group_by(inhalant_gen, inhalant_type2) %>%
#   dplyr::summarise(
#     all_products = "all_products",
#     count_groupings = count_groupings[1],
#     count_products = n()
#   ) %>%
#   as.data.frame()
# 
# colnames(edges) <- c("N2", "N3", "N1", "Value_1", "Value_2")
# # reorder columns
# edges <- edges[, c("N1", "N2", "Value_1", "N3", "Value_2")]
# 
# nodes <- data.frame(
#   ID = c(unique(edges$N1), unique(edges$N2), unique(edges$N3)), stringsAsFactors= FALSE,
#   col = c(rep("blue"),
#           rep("#e8008077", length(unique(sankey.df$inhalant_type))), 
#           rep("#4a7aff77", length(unique(sankey.df$inhalant_gen))))
# )
# 
# riv <- makeRiver(nodes, edges, 
#                  node_xpos=c(rep.int(1,length(unique(edges$N1))), 
#                              rep.int(2,length(unique(edges$N2))), 
#                              rep.int(3,length(unique(edges$N3)))))
# 
# # style the riverplot
# riv.style <- riverplot::default.style()
# riv.style$textcex <- 0.7
# riv.style$srt <- 0
# riv.style$nodestyle <- "regular"
# riv.style$textcol <- "#39383a"
# #riv.style$edgecol$col <- "#FF0000"
# #riv.style$colorRampPaletteAlpha( c( "#FF000033", "#00FF0099" ) )( 5 )
# plot(riv, default_style=riv.style, node_margin=0.2, plot_area=1, xscale=0.92)
# text(-.18, .5, "Product Groupings", col= "#333333", cex=0.8, srt = 90)
# text(1, .5, "Product Types", col= "#333333", srt = 270, cex=0.8)






```
